<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Day 80 Lab - Mini-Project: Tiny Log Analyzer (CLI+)</title>
  <link rel="stylesheet" href="../assets/lab.css" />
</head>
<body>
  <div class="lab-container">
    <h1>Day 80 Lab</h1>
    <h2>Mini‚ÄëProject ‚Äî Tiny Log Analyzer (CLI+)</h2>

    <p><strong>Objective:</strong> Build a robust command-line log analyzer that accepts one or more files, supports keyword and level filters, tallies counts, extracts IPs, and optionally writes a report to disk ‚Äî with real error handling.</p>

    <h3>üõ† Tools Needed</h3>
    <ul>
      <li>Python 3</li>
      <li>VS Code with Python extension</li>
    </ul>

    <h3>What You‚Äôll Build</h3>
    <p>A CLI tool: <code>log_analyzer.py</code> that can:</p>
    <ul>
      <li>Read <em>one or more</em> log files (paths or globs).</li>
      <li>Filter by <code>--keyword</code> (with optional <code>--ignore-case</code>).</li>
      <li>Filter by <code>--level</code> (detects <code>ERROR/WARN/INFO/DEBUG/CRITICAL</code> anywhere in line).</li>
      <li>Count repeated lines and show <code>--top</code> N.</li>
      <li><code>--ips</code>: extract and count IPv4 addresses.</li>
      <li>Write a nicely formatted report to <code>--out</code> (optional).</li>
      <li>Gracefully handle missing files and other I/O errors.</li>
    </ul>

    <h3>Starter Log Format (example)</h3>
    <p>Works with free‚Äëform logs; level detection uses regex. Example lines:</p>
<pre><code>2025-08-10 10:01:22Z INFO User jkim logged in from 10.0.0.1
2025-08-10 10:05:03Z ERROR Permission denied for tsmith (10.0.0.2)
2025-08-10 10:05:05Z WARN High CPU on host web01 (10.0.0.3)
2025-08-10 10:05:07Z INFO User jkim logged out
</code></pre>

    <h3>Step 1 ‚Äî Project File</h3>
    <p>Create <code>log_analyzer.py</code> with the following (complete) starter implementation:</p>
<pre><code>#!/usr/bin/env python3
"""
Tiny Log Analyzer (CLI+)
- Read one or more files (or --stdin)
- Optional keyword and level filters
- Count repeated lines; show top N
- Extract and count IPs
- Optional report output to a file
"""
from __future__ import annotations
import sys, re, argparse
from pathlib import Path
from collections import Counter
from typing import Iterable, Iterator, Sequence

LEVEL_RE = re.compile(r"\b(ERROR|WARN|WARNING|INFO|DEBUG|CRITICAL)\b", re.IGNORECASE)
IP_RE    = re.compile(r"\b(?:\d{1,3}\.){3}\d{1,3}\b")

def iter_lines(paths: Sequence[Path]) -> Iterator[str]:
    """Yield lines from all files (utf-8), skipping unreadable ones with a warning."""
    for p in paths:
        try:
            with p.open("r", encoding="utf-8", errors="replace") as f:
                for line in f:
                    yield line.rstrip("\n")
        except FileNotFoundError:
            print(f"[WARN] Missing file: {p}", file=sys.stderr)
        except OSError as e:
            print(f"[WARN] Could not read {p}: {e}", file=sys.stderr)

def filter_keyword(lines: Iterable[str], keyword: str, ignore_case: bool) -> Iterator[str]:
    if not keyword:
        yield from lines
        return
    if ignore_case:
        kw = keyword.lower()
        for ln in lines:
            if kw in ln.lower():
                yield ln
    else:
        for ln in lines:
            if keyword in ln:
                yield ln

def filter_level(lines: Iterable[str], level: str | None) -> Iterator[str]:
    if not level:
        yield from lines
        return
    lvl = level.upper()
    for ln in lines:
        m = LEVEL_RE.search(ln)
        if m and m.group(1).upper().startswith(lvl):  # "WARN" matches "WARNING"
            yield ln

def count_lines(lines: Iterable[str]) -> Counter[str]:
    c = Counter()
    for ln in lines:
        if ln.strip():
            c[ln] += 1
    return c

def count_ips(lines: Iterable[str]) -> Counter[str]:
    c = Counter()
    for ln in lines:
        for ip in IP_RE.findall(ln):
            c[ip] += 1
    return c

def format_table(title: str, pairs: Sequence[tuple[str,int]], width: int = 60) -> str:
    out = [f"=== {title} ==="]
    for k, v in pairs:
        left = (k[:width-10] + "‚Ä¶") if len(k) > width-3 else k
        out.append(f"{left.ljust(width)} {v}")
    return "\n".join(out)

def main(argv: Sequence[str] | None = None) -> int:
    ap = argparse.ArgumentParser(description="Tiny Log Analyzer (CLI+)")
    ap.add_argument("paths", nargs="*", help="Log file paths (accepts globs on most shells)")
    ap.add_argument("--stdin", action="store_true", help="Read from STDIN instead of files")
    ap.add_argument("--keyword", help="Only count lines containing this keyword")
    ap.add_argument("--ignore-case", action="store_true", help="Case-insensitive keyword match")
    ap.add_argument("--level", choices=["ERROR","WARN","WARNING","INFO","DEBUG","CRITICAL"],
                    help="Filter by detected level")
    ap.add_argument("--top", type=int, default=10, help="Show top N results (default: 10)")
    ap.add_argument("--ips", action="store_true", help="Extract and count IPv4 addresses")
    ap.add_argument("--out", type=Path, help="Write report to this file instead of stdout")
    args = ap.parse_args(argv)

    # Collect input lines
    if args.stdin:
        src_lines = (ln.rstrip("\n") for ln in sys.stdin)
    else:
        if not args.paths:
            ap.error("Provide at least one path or use --stdin")
        paths = [Path(p) for p in args.paths]
        src_lines = iter_lines(paths)

    # Apply filters in sequence
    ln1 = filter_keyword(src_lines, args.keyword or "", args.ignore_case)
    ln2 = filter_level(ln1, args.level)

    # Count lines and (optionally) IPs
    line_counts = count_lines(ln2)
    top_lines = line_counts.most_common(args.top)

    # For IP counting, we must re-run filters over source (generators are one-pass).
    # Reconstruct pipeline:
    if args.stdin:
        # If reading from stdin, we already consumed it; warn and skip IPs
        ip_counts = Counter()
        if args.ips:
            print("[WARN] --ips ignored with --stdin (stream already consumed). Pipe twice if needed.", file=sys.stderr)
    else:
        paths = [Path(p) for p in args.paths]
        ln_ip = filter_level(filter_keyword(iter_lines(paths), args.keyword or "", args.ignore_case), args.level)
        ip_counts = count_ips(ln_ip) if args.ips else Counter()

    # Build report text
    report_parts = []
    report_parts.append(format_table("Top Lines", top_lines))
    if args.ips:
        report_parts.append(format_table("Top IPs", ip_counts.most_common(args.top)))
    report = "\n\n".join(report_parts) + "\n"

    # Output
    if args.out:
        try:
            args.out.parent.mkdir(parents=True, exist_ok=True)
            args.out.write_text(report, encoding="utf-8")
            print(f"[OK] Wrote report -> {args.out}")
        except OSError as e:
            print(f"[ERROR] Could not write report: {e}", file=sys.stderr)
            print(report)  # fallback to stdout
    else:
        print(report)

    return 0

if __name__ == "__main__":
    raise SystemExit(main())
</code></pre>

    <h3>Step 2 ‚Äî How to Run</h3>
    <p>Create a file <code>sample.log</code> (use the sample lines above) and try:</p>
<pre><code># Basic
python log_analyzer.py sample.log

# Filter by keyword and show top 5
python log_analyzer.py sample.log --keyword "User" --ignore-case --top 5

# Filter by level (WARN will also match WARNING)
python log_analyzer.py sample.log --level WARN

# Count IPs too, save report to a file
python log_analyzer.py sample.log --ips --out reports/summary.txt

# Multiple files
python log_analyzer.py logs/app1.log logs/app2.log --ips --top 20
</code></pre>

    <h3>Mini Lab ‚Äî Keyword Filter (CLI option)</h3>
    <p>Add <code>--keyword</code> (already included above) and verify it only counts lines containing the keyword. Include <code>--ignore-case</code> for case‚Äëinsensitive matching. Show two runs: one with, one without the filter.</p>

    <h3>Mini Lab ‚Äî Level Filter (Regex)</h3>
    <p>Use the built‚Äëin <code>--level</code> to show only <code>ERROR/WARN/INFO/DEBUG/CRITICAL</code>. Confirm that <code>WARN</code> matches <code>WARNING</code> lines.</p>

    <h3>Mini Lab ‚Äî Top IPs</h3>
    <p>Run with <code>--ips</code> to extract and count IPv4 addresses. Show the top 5 with <code>--top 5</code>.</p>

    <h3>‚úÖ Deliverables</h3>
    <ul>
      <li>Screenshot of terminal showing a basic run and a filtered run (<code>--keyword</code> or <code>--level</code>).</li>
      <li>Screenshot of a run with <code>--ips</code> and the resulting ‚ÄúTop IPs‚Äù section.</li>
      <li>Screenshot of the saved report file when using <code>--out</code> (open the text file to show content).</li>
    </ul>

    <h3>üéØ Stretch Goals (Optional)</h3>
    <ul>
      <li><strong>CSV Export:</strong> Add <code>--csv &lt;path&gt;</code> to write <code>entry,count</code> plus an optional <code>ip,count</code> sheet.</li>
      <li><strong>Glob Input:</strong> Accept patterns like <code>logs/*.log</code> (your shell may expand these automatically).</li>
      <li><strong>Stdin Mode:</strong> Support <code>--stdin</code> and demonstrate piping: <code>type sample.log | python log_analyzer.py --stdin --ips</code>.</li>
      <li><strong>Exit Codes:</strong> Return non‚Äëzero if no files were readable or if zero lines matched after filters.</li>
      <li><strong>Configurable Level Regex:</strong> Add <code>--levels</code> to supply a custom regex (advanced).</li>
    </ul>

    <h3>üß† Reflect</h3>
    <ol>
      <li>Where did error handling make the tool more reliable (missing file, unreadable file, bad output path)?</li>
      <li>What‚Äôs the benefit of reconstructing the pipeline for IP counting (one‚Äëpass generators)?</li>
      <li>How would you package this as a reusable module or turn it into a small internal tool at work?</li>
    </ol>

    <hr />
    <p><strong>Lab Summary:</strong> You built a practical CLI utility that reads files, filters/aggregates with dictionaries and regex, handles errors cleanly, and writes reports. This is a portfolio‚Äëready mini tool you can extend with CSV, JSON, or richer parsing later.</p>
  </div>
</body>
</html>
